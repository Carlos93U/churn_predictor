# churn_predictor
A predictive analytics tool, forecasting customer attrition to enhance retention strategies.

========================================================
Un dashboard del analisis de datos (graficos)
Codigo Comentado 
Codigo documentado (Teoria de sklearn)
anade gifts

En la lectura de datos indicar a que se refieren cada columna

Data pre-processing
	● Eliminar duplicados.
	● Evaluar valores nulos (profundiza en la libreria missingno)
	● Remover columnas innecesarias.
	● Procesar datos categóricos.
	● Remover outliers.
	● Escalar data.


Data Analisys:
	analisis de correlacion

Documentation

========================================================
Buscar informacion en tesis o articulos que hablen sobre la regresion logistica 
y la matematica detras de ella
informacion de la los modelos de regresion logistica de sklearn
========================================================


EXAMPLE

# WEB_SCRAPING_EVENTS_COES | <img src="https://upload.wikimedia.org/wikipedia/commons/thumb/c/c3/Python-logo-notext.svg/800px-Python-logo-notext.svg.png" height=20> | <img src="https://i.postimg.cc/gJCvVKsy/scrapy.png" height=20>| <img src="https://i.postimg.cc/fLtcSPcT/coes-logo.png" height=20> | [<img src="https://static-00.iconduck.com/assets.00/github-icon-2048x1988-jzvzcf2t.png" height=20> ](https://github.com/Carlos93U) | [<img src="https://upload.wikimedia.org/wikipedia/commons/thumb/c/ca/LinkedIn_logo_initials.png/640px-LinkedIn_logo_initials.png" height=20>](https://www.linkedin.com/in/juan-carlos-huillcas/) | [<img src="https://play-lh.googleusercontent.com/lMoItBgdPPVDJsNOVtP26EKHePkwBg-PkuY9NOrc-fumRtTFP4XhpUNk_22syN4Datc=w240-h480-rw" height=20>](https://www.youtube.com/channel/UCYu373DAK-zuhDTFCZNgyPQ) 

## 1. Resume

    This project utilizes the Scrapy framework in Python to perform web scraping on a website, extracting information about the latest events in the Peruvian national electrical system. The website is https://www.coes.org.pe/Portal/home/

[![coes.gif](https://i.postimg.cc/Nj8jsFtb/coes.gif)](https://postimg.cc/VJ684Ydb)

## 2. About
    
    In this project, several web scraping methods are demonstrated, including the creation of spiders in Scrapy to gather lists of events and formatting the output using a JSON file. The project also adheres to security protocols such as respecting the contents of robots.txt. With the JSON output format, we could leverage it to provide updated information support to third-party websites.

## 3. Setting up

*Create a virtual enviroment with:*

```
python3 -m venv env

```
*Activate virtual enviroment:*

```
source env/bin/activate
```

*Install requirements.txt:*

```
pip install -r requirements.txt
```
*Verify modules:*

```
scrapy version 
Output:"Scrapy 2.11.0"
```

## 4. Running
*Go to directory datacoes:*

```
cd datacoes
```
*Run command*

```
scrapy crawl scrap_events
```
[![code.gif](https://i.postimg.cc/8CQNxr0t/code.gif)](https://postimg.cc/Yv35WjkW)
## 5. Extensions in use

    JC : JSON Crack

## 6. Documentation

* [Python](https://www.python.org/doc/) - Python's documentation, tutorials, and guides are constantly evolving.
* [Scrapy](https://docs.scrapy.org/en/latest/) - Documentation about Scrapy
* [Class and Objects - OOP](https://docs.python.org/es/3/tutorial/classes.html) - Object oriented programming


## 7. Updates

**01/22/2024**</br>
First version

## 8. Author

* **Juan Huillcas A** 
* **Email_1 : huillcas.juan3@gmail.com**
* **Email_2 : juan.huillcas.a@uni.pe**
